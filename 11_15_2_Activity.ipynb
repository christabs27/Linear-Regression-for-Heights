{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christabs27/Linear-Regression-for-Heights/blob/main/11_15_2_Activity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4n9TsbGw-f"
      },
      "source": [
        "# Activity 11.15.2\n",
        "\n",
        "Generative Adversarial Networks (GANs) are fascinating because they have two parts: one part that creates and one part that classifies.  In this activity, we are going to train a GAN to learn to write the numbers 0–9 in a handwriting style.  \n",
        "\n",
        "The [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains images of the numbers 0–9 written in different handwriting styles.  We will use this set of images to train the GAN to write and recognize handwritten numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1: Install the necessary packages\n",
        "**Note**: You are importing several unfamiliar packages that will allow you to animate the GAN learning process.\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "!pip install imageio\n",
        "!pip install git+https://github.com/tensorflow/docs\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from IPython import display\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "eOE0IPoIQ91v"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z682XYsrjkY9"
      },
      "source": [
        "#Step 1\n",
        "import tensorflow as tf\n",
        "!pip install imageio\n",
        "!pip install git+https://github.com/tensorflow/docs\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from IPython import display\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2: Import the MNIST dataset\n",
        "* Run the following code block to load the data.\n",
        "* `train_images` and `train_labels` contain the images and labels for the MNIST images used to train the GAN."
      ],
      "metadata": {
        "id": "XFPqYHAVqDC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2\n",
        "\n",
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "7hpGXDOkwWk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Pre-process the image data\n",
        "* Run the following code block to prepare the data for modeling.\n",
        "* The first step reshapes the training image matrix.\n",
        "* The second step scales the values of the pixels from -1 to +1.\n",
        "* Recall that batching and buffering the data is used to speed up the model building process by allowing different parts of the model to be trained using different parts of the data at the same time."
      ],
      "metadata": {
        "id": "x6ETJREm_dZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3\n",
        "\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5  \n",
        "\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "eIVIHbiNwZso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Define the generator\n",
        "Run the following code block to create the generator part of our model."
      ],
      "metadata": {
        "id": "L_zWz_YqBT4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4\n",
        "\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "a3qASmlfxBe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 5: Use the generator to create an image\n",
        "* Right now, the generator is untrained, so the first image it produces should look like random noise.\n",
        "* It will be up to the discriminator, which you will build next, to guide the generator toward producing images that actually look like handwritten numbers."
      ],
      "metadata": {
        "id": "-OTSop4Tm27l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5:\n",
        "\n",
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ],
      "metadata": {
        "id": "WaaUBiBmmVhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 6: Define the discriminator\n",
        "Run the following code block to define the discriminator part of the GAN."
      ],
      "metadata": {
        "id": "wzAm-CMXAP8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6:\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "CBR5fk4Pwn9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 7: Define the Discriminator\n",
        "Use the (as yet untrained) discriminator to classify the generated images as real or fake. The model will be trained to output positive values for real images, and negative values for fake images."
      ],
      "metadata": {
        "id": "OQfYA2BX4C7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 7\n",
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ],
      "metadata": {
        "id": "ZBCJbfFQ4COR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 8: Compile and train the GAN\n",
        "* Run the following code to compile and train the GAN.  *(Note: This step can take several minutes.)*\n",
        "* Scroll down to the bottom to see the evolution of the GAN learning to draw numbers while you wait for the model to compile.\n",
        "* It takes about 50 epochs for the numbers generated by the GAN to begin to look like the MNIST numbers.  \n",
        "* If you have time later, increase the number of epochs from 50 in the code below."
      ],
      "metadata": {
        "id": "HJq5EimlEZ0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 8\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)\n",
        "  \n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n",
        "\n",
        "train(train_dataset, EPOCHS)\n",
        "\n"
      ],
      "metadata": {
        "id": "rGXqh3kyxZzG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}